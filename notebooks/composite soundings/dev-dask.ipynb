{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "608ca6fd-f04c-4d7e-88dc-9917e7d95ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from metpy.calc import dewpoint_from_relative_humidity\n",
    "from metpy.units import units\n",
    "from metpy.plots import SkewT\n",
    "\n",
    "import sounding_utils\n",
    "from xhistogram.xarray import histogram\n",
    "\n",
    "from importlib import reload\n",
    "from functools import partial\n",
    "from joblib import dump\n",
    "\n",
    "import sys\n",
    "#sys.path.append('../../') # lets us import ptype package from the subdir\n",
    "\n",
    "#import ptype.\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from dask_jobqueue import PBSCluster\n",
    "import dask\n",
    "import glob\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "94480eba-97b0-4756-92d7-8c2c4370fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a108429f-20d1-4983-8ae6-2d70e9b875ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use this link to monitor the workload: https://jupyterhub.hpc.ucar.edu/stable/user/dkimpara/phil/proxy/8787/status\n"
     ]
    }
   ],
   "source": [
    "cluster = PBSCluster(account='NAML0001',\n",
    "                     queue='casper',\n",
    "                     walltime='01:00:00',\n",
    "                     memory=\"1000 GB\",\n",
    "                     resource_spec='select=1:ncpus=16:mem=50GB', # Specify resources\n",
    "                     interface='ib0',\n",
    "                     local_directory='/glade/work/dkimpara/dask/',\n",
    "                     log_directory=\"/glade/work/dkimpara/dask_logs/\")\n",
    "\n",
    "# Change your url to the dask dashboard so you can see it\n",
    "#dask.config.set({'distributed.dashboard.link':'https://jupyterhub.hpc.ucar.edu/stable/user/{USER}/proxy/{port}/status'})\n",
    "print(f\"Use this link to monitor the workload: {cluster.dashboard_link}\")\n",
    "client = Client(cluster)\n",
    "cluster.scale(jobs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0671b8e0-50a1-4f29-b1d5-865c0b1d04e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-aac9921c-1468-11ee-b01c-3cecef1ac748</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_jobqueue.PBSCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"https://jupyterhub.hpc.ucar.edu/stable/user/dkimpara/phil/proxy/8787/status\" target=\"_blank\">https://jupyterhub.hpc.ucar.edu/stable/user/dkimpara/phil/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">PBSCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">4b070f96</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"https://jupyterhub.hpc.ucar.edu/stable/user/dkimpara/phil/proxy/8787/status\" target=\"_blank\">https://jupyterhub.hpc.ucar.edu/stable/user/dkimpara/phil/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-e8c2229c-b955-4fb0-ac13-1716a461d9ca</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://10.12.206.56:34430\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"https://jupyterhub.hpc.ucar.edu/stable/user/dkimpara/phil/proxy/8787/status\" target=\"_blank\">https://jupyterhub.hpc.ucar.edu/stable/user/dkimpara/phil/proxy/8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.12.206.56:34430' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "420e1e4d-0b0d-471a-8715-e5a13f05f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dask(model):\n",
    "    with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
    "        ds = xr.open_mfdataset(f\"/glade/campaign/cisl/aiml/ptype/ptype_case_studies/kentucky/{model}/*/*/*.nc\", \n",
    "                               parallel=True, engine='netcdf4', \n",
    "                               decode_cf=False, concat_dim='valid_time', combine='nested', \n",
    "                               chunks={'time':1, 'heightAboveGround': 21, 'isobaricInhPa': 37})\n",
    "        ds.attrs['nwp'] = model\n",
    "        return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e692130c-2182-4f32-8cf0-662792a363d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## aggregation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8f201ed-a42d-4306-af9d-6c1ab2510877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_stats(ds, save_dir='/glade/scratch/dkimpara/composite_calcs'):\n",
    "    with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
    "        try:\n",
    "            print(ds.attrs['nwp'])\n",
    "        except: \n",
    "            raise ValueError('dataset must have nwp attr set')\n",
    "\n",
    "        ds = sounding_utils.filter_latlon(ds)\n",
    "\n",
    "        precip_mask = (\n",
    "            (ds[\"crain\"] == 1)\n",
    "            | (ds[\"csnow\"] == 1)\n",
    "            | (ds[\"cicep\"] == 1)\n",
    "            | (ds[\"cfrzr\"] == 1)\n",
    "            )\n",
    "\n",
    "        ds = ds.where(precip_mask)\n",
    "        if 'wb_h' not in list(ds.keys()):\n",
    "            ds = sounding_utils.wet_bulb_from_rel_humid(ds)\n",
    "\n",
    "        ptypes = ['rain', 'snow', 'icep', 'frzr']\n",
    "        prof_vars = ['t_h', 'dpt_h', 'wb_h']\n",
    "        bins = np.arange(-40, 40, 0.5)\n",
    "        quantiles = np.arange(0.0, 1.01, 0.1)\n",
    "\n",
    "        persist_vars = (prof_vars + \n",
    "                        [f'ML_c{var}' for var in ptypes] +\n",
    "                        [f'c{var}' for var in ptypes])\n",
    "\n",
    "        ds[persist_vars].persist() \n",
    "        total_obs = ds.t_h.isel(heightAboveGround=0).count(dim=('x','y','time','valid_time'))\n",
    "\n",
    "        res_dict = {'mean': [],\n",
    "                    'quantiles': [],\n",
    "                    'hist': [],\n",
    "                    }\n",
    "        metadata = {'total_obs': total_obs}\n",
    "\n",
    "        for ptype in ptypes:\n",
    "            for model in ['ML_c', 'c']:\n",
    "                predtype = model + ptype\n",
    "                subset = ds[prof_vars].where(ds[predtype] == 1)\n",
    "\n",
    "                ### num_obs per hr\n",
    "                counts = subset.t_h.count(dim=('x','y'))\n",
    "                obs_per_hr = counts.isel(heightAboveGround=0).mean(dim=('time', 'valid_time'))\n",
    "                metadata[f'{predtype}_obs_per_hr'] = obs_per_hr\n",
    "\n",
    "                # num_obs of predtype==1\n",
    "                num_obs = subset.t_h.isel(heightAboveGround=0).count(dim=('x','y','time','valid_time'))\n",
    "                metadata[f'{predtype}_num_obs'] = num_obs\n",
    "\n",
    "                # num_obs w frac abv zero\n",
    "                for var in prof_vars:\n",
    "                    metadata[f\"{predtype}_{var}_frac_abv_zero\"] = (\n",
    "                        sounding_utils.frac_abv_zero(subset, var, num_obs)\n",
    "                    )\n",
    "\n",
    "                # means and quantiles\n",
    "                mean = subset.mean(dim=('valid_time', 'time', 'x', 'y')) #returns dataset objects\n",
    "                mean = mean.rename({var: f'{var}_mean' for var in prof_vars})\n",
    "                \n",
    "                qs = subset.quantile(quantiles, dim=('valid_time', 'time', 'x', 'y')) #returns dataset objects\n",
    "                qs = qs.rename({var: f'{var}_qs' for var in prof_vars})\n",
    "                \n",
    "                #### densities ####\n",
    "                densities = ({f'{var}_hist': (\n",
    "                        histogram(subset[var], bins=bins, dim=['valid_time', 'time', 'x', 'y'], density=True)\n",
    "                        .rename({f'{var}_bin': 'bin'})\n",
    "                        ) for var in prof_vars})\n",
    "                densities = xr.Dataset(densities) #arrays already named histograms\n",
    "\n",
    "                res_datasets = {'mean': mean,\n",
    "                            'quantiles': qs,\n",
    "                            'hist': densities}\n",
    "\n",
    "                for k, res_ds_list in res_dict.items():\n",
    "                    res_ds_list.append(res_datasets[k].expand_dims({'predtype': [predtype]}))\n",
    "                \n",
    "        ds_concat = [xr.concat(res_ds_list, dim='predtype') for res_ds_list in res_dict.values()]\n",
    "        result = xr.merge(ds_concat)\n",
    "        #save\n",
    "        result.to_netcdf(path=join(save_dir, ds.attrs['nwp']))\n",
    "        dump(metadata, join(save_dir,f\"{ds.attrs['nwp']}_metadata\"))\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1dc3faa7-9871-4b07-ba7c-880b96ff631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_delayed(ds, save_dir='/glade/scratch/dkimpara/composite_calcs'):\n",
    "    with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
    "        try:\n",
    "            print(ds.attrs['nwp'])\n",
    "        except: \n",
    "            raise ValueError('dataset must have nwp attr set')\n",
    "\n",
    "        ds = sounding_utils.filter_latlon(ds)\n",
    "\n",
    "        precip_mask = (\n",
    "            (ds[\"crain\"] == 1)\n",
    "            | (ds[\"csnow\"] == 1)\n",
    "            | (ds[\"cicep\"] == 1)\n",
    "            | (ds[\"cfrzr\"] == 1)\n",
    "            )\n",
    "\n",
    "        ds = ds.where(precip_mask)\n",
    "        print('filtered')\n",
    "        #if 'wb_h' not in list(ds.keys()):\n",
    "        #    ds = sounding_utils.wet_bulb_from_rel_humid(ds)\n",
    "        #print('wb computed')\n",
    "        ptypes = ['rain', 'snow', 'icep', 'frzr']\n",
    "        prof_vars = ['t_h', 'dpt_h']#, 'wb_h']\n",
    "        bins = np.arange(-40, 40, 0.5)\n",
    "        quantiles = np.arange(0.0, 1.01, 0.1)\n",
    "\n",
    "        persist_vars = (prof_vars + \n",
    "                        [f'ML_c{var}' for var in ptypes] +\n",
    "                        [f'c{var}' for var in ptypes])\n",
    "\n",
    "        #ds[persist_vars].persist() \n",
    "        print('persisted')\n",
    "        total_obs = ds.t_h.isel(heightAboveGround=0).count(dim=('x','y','time','valid_time'))\n",
    "\n",
    "        res_dict = {'mean': [],\n",
    "                    quantiles': [],\n",
    "                    'hist': [],\n",
    "                    }\n",
    "        metadata = {'total_obs': total_obs}\n",
    "        print('total obs')\n",
    "\n",
    "        lazy_results = []\n",
    "        ####################################\n",
    "        remote_ds = client.scatter(ds)\n",
    "        for ptype in ptypes:\n",
    "            for model in ['ML_c', 'c']:\n",
    "                predtype = model + ptype\n",
    "                \n",
    "                lazy_result = dask.delayed(agg_parallel)(predtype, remote_ds) #this fn returns a dict of datasets\n",
    "                lazy_results.append(lazy_result)\n",
    "                \n",
    "        print('computing')\n",
    "        for i in range(len(ptypes)):\n",
    "            res, meta = lazy_results[i].compute()\n",
    "            metadata = metadata | meta #merge metadata dictionary\n",
    "            for k in res.keys():\n",
    "                res_dict[k].append(res[k])\n",
    "        print('extracted')\n",
    "        ds_concat = [xr.concat(res_ds_list, dim='predtype') for res_ds_list in res_dict.values()]\n",
    "        result = xr.merge(ds_concat)\n",
    "        #save\n",
    "        result.to_netcdf(path=join(save_dir, ds.attrs['nwp']))\n",
    "        dump(metadata, join(save_dir, f\"{ds.attrs['nwp']}_metadata\"))\n",
    "\n",
    "        return result\n",
    "\n",
    "def agg_parallel(predtype, ds):\n",
    "    metadata = {}\n",
    "    prof_vars = ['t_h', 'dpt_h']\n",
    "    bins = np.arange(-40, 40, 0.5)\n",
    "    quantiles = np.arange(0.0, 1.01, 0.1)\n",
    "    \n",
    "    subset = ds[prof_vars].where(ds[predtype] == 1)\n",
    "\n",
    "    ### num_obs per hr\n",
    "    counts = subset.t_h.count(dim=('x','y'))\n",
    "    obs_per_hr = counts.isel(heightAboveGround=0).mean(dim=('time', 'valid_time'))\n",
    "    metadata[f'{predtype}_obs_per_hr'] = obs_per_hr\n",
    "\n",
    "    # num_obs of predtype==1\n",
    "    num_obs = subset.t_h.isel(heightAboveGround=0).count(dim=('x','y','time','valid_time'))\n",
    "    metadata[f'{predtype}_num_obs'] = num_obs\n",
    "\n",
    "    # num_obs w frac abv zero\n",
    "    for var in prof_vars:\n",
    "        metadata[f\"{predtype}_{var}_frac_abv_zero\"] = (\n",
    "            frac_abv_zero(subset, var, num_obs)\n",
    "        )\n",
    "\n",
    "    # means and quantiles\n",
    "    mean = subset.mean(dim=('valid_time', 'time', 'x', 'y')) #returns dataset objects\n",
    "    mean = mean.rename({var: f'{var}_mean' for var in prof_vars})\n",
    "\n",
    "    qs = subset.chunk(dict(valid_time=-1, time=-1)).quantile(quantiles, dim=('valid_time', 'time', 'x', 'y')) #returns dataset objects\n",
    "    qs = qs.rename({var: f'{var}_qs' for var in prof_vars})\n",
    "\n",
    "    #### densities ####\n",
    "    densities = ({f'{var}_hist': (\n",
    "            histogram(subset[var], bins=bins, dim=['valid_time', 'time', 'x', 'y'], density=True)\n",
    "            .rename({f'{var}_bin': 'bin'})\n",
    "            ) for var in prof_vars})\n",
    "    densities = xr.Dataset(densities) #arrays already named histograms\n",
    "\n",
    "    res_datasets = {'mean': mean,\n",
    "                'quantiles': qs,\n",
    "                'hist': densities}\n",
    "    return res_datasets, metadata\n",
    "\n",
    "def frac_abv_zero(ds, x_col, total):\n",
    "    num_over_zero = (ds[x_col] > 0).any(dim=\"heightAboveGround\").sum()\n",
    "    return num_over_zero / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480133fa-45b6-4a29-808f-b294dde58cde",
   "metadata": {},
   "source": [
    "# run jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b5787bc-ff07-4a03-9c89-e3f1aaa7de02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 49s, sys: 17.4 s, total: 5min 7s\n",
      "Wall time: 12min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = 'rap'\n",
    "ds = load_dask(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f89e6df-26b1-4d4c-bf1b-5ac16d2d1674",
   "metadata": {},
   "source": [
    "%%time\n",
    "reload(sounding_utils)\n",
    "res_rap = agg_delayed(ds)\n",
    "del ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d53a9522-5b1f-43ef-86de-10ef20877d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rap\n",
      "filtered\n",
      "persisted\n",
      "total obs\n"
     ]
    }
   ],
   "source": [
    "dask.config.set(**{'array.slicing.split_large_chunks': True})\n",
    "try:\n",
    "    print(ds.attrs['nwp'])\n",
    "except: \n",
    "    raise ValueError('dataset must have nwp attr set')\n",
    "\n",
    "ds = sounding_utils.filter_latlon(ds)\n",
    "\n",
    "precip_mask = (\n",
    "    (ds[\"crain\"] == 1)\n",
    "    | (ds[\"csnow\"] == 1)\n",
    "    | (ds[\"cicep\"] == 1)\n",
    "    | (ds[\"cfrzr\"] == 1)\n",
    "    )\n",
    "\n",
    "ds = ds.where(precip_mask)\n",
    "print('filtered')\n",
    "#if 'wb_h' not in list(ds.keys()):\n",
    "#    ds = sounding_utils.wet_bulb_from_rel_humid(ds)\n",
    "#print('wb computed')\n",
    "ptypes = ['rain', 'snow', 'icep', 'frzr']\n",
    "prof_vars = ['t_h', 'dpt_h']#, 'wb_h']\n",
    "bins = np.arange(-40, 40, 0.5)\n",
    "quantiles = np.arange(0.0, 1.01, 0.1)\n",
    "\n",
    "persist_vars = (prof_vars + \n",
    "                [f'ML_c{var}' for var in ptypes] +\n",
    "                [f'c{var}' for var in ptypes])\n",
    "\n",
    "#ds[persist_vars].persist() \n",
    "print('persisted')\n",
    "total_obs = ds.t_h.isel(heightAboveGround=0).count(dim=('x','y','time','valid_time'))\n",
    "\n",
    "res_dict = {'mean': [],\n",
    "            #quantiles': [],\n",
    "            'hist': [],\n",
    "            }\n",
    "metadata = {'total_obs': total_obs}\n",
    "print('total obs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c099d10-b400-42f2-a665-fd3e414664c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.08 s, sys: 3.38 s, total: 10.5 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lazy_results = []\n",
    "remote_ds = client.scatter(ds)\n",
    "\n",
    "for ptype in ptypes:\n",
    "    for model in ['ML_c', 'c']:\n",
    "        predtype = model + ptype\n",
    "\n",
    "        lazy_result = dask.delayed(agg_parallel)(predtype, remote_ds) #this fn returns a dict of datasets and a metadata dict\n",
    "        lazy_results.append(lazy_result)\n",
    "        \n",
    "        #lazy_result.append(agg_parallel(predtype, ds))\n",
    "#need to do client.gather to compute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "175991b8-4d93-4289-b681-123df94f1b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted\n",
      "CPU times: user 19.7 s, sys: 3.45 s, total: 23.1 s\n",
      "Wall time: 37.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(ptypes)):\n",
    "    res, meta = lazy_results[i].compute()\n",
    "    metadata = metadata | meta #merge metadata dictionary\n",
    "    for k in res.keys():\n",
    "        res_dict[k].append(res[k])\n",
    "print('extracted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed93902d-a37a-452b-b080-15982b73b276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/dkimpara/conda-envs/ptype/lib/python3.10/site-packages/distributed/client.py:3109: UserWarning: Sending large graph of size 23.51 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 17s, sys: 35.4 s, total: 14min 52s\n",
      "Wall time: 25min 50s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/glade/scratch/dkimpara/composite_calcs/rap_metadata']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ds_concat = [xr.concat(res_ds_list, dim='predtype') for res_ds_list in res_dict.values()]\n",
    "result = xr.merge(ds_concat)\n",
    "#save\n",
    "save_dir='/glade/scratch/dkimpara/composite_calcs'\n",
    "result.to_netcdf(path=join(save_dir, ds.attrs['nwp']))\n",
    "dump(metadata, join(save_dir, f\"{ds.attrs['nwp']}_metadata\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629f417b-db0b-4ef4-bb99-8e6e5233700d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be0ca555-91a4-404c-a0f3-5ce50a14684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(tic):\n",
    "    toc = time.time()\n",
    "    duration = toc - tic\n",
    "    minutes = int(duration/60)\n",
    "    print(f\"Elapsed time: {str(minutes) + ' minutes, ' if minutes else ''}{int(duration % 60)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16edbcbc-78ff-4c37-b005-7ae077db2968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for model in ['rap', 'gfs', 'hrrr']:\n",
    "    tic = time.time()\n",
    "    ds = load_dask(model)\n",
    "    timer(tic)\n",
    "    \n",
    "    tic = time.time()\n",
    "    _ = agg_stats(ds)\n",
    "    timer(tic)\n",
    "    del ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6532942-8319-44eb-9480-f3fa229e85cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = 'gfs'\n",
    "ds = load_dask(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7e617d-a3f8-4433-9df0-a1b33d7b14d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res_gfs = agg_stats(ds)\n",
    "del ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46085da1-ee73-45a4-8da5-a042d308d488",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = 'hrrr'\n",
    "ds = load_dask(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c65931-7249-427b-aa02-db743c4bc187",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res_hrrr = agg_stats(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b983b25-1ce1-4af5-875e-c69f03a9257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()\n",
    "import subprocess\n",
    "subprocess.run(\"qdel $PBS_JOBID\", shell=True, capture_output=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1032fa76-ef88-49d3-adaa-36e6e238cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7daa86-f839-4102-8ded-369c421f2a74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ptype]",
   "language": "python",
   "name": "conda-env-ptype-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
